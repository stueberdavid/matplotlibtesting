Meeting 02.05.24

über die Zeit betrachten, mit der Zeitspalte frame.time_epoche
y = Zeit, x = nicht alle Pakete als Summe, sondern Pakete bzw. Byte pro Sec.
Videostreams in verschiedenen Qualitäten anfordern und vergleichen in einem gemeinsamen Plot
wie viel von der frame.len nur header, wie viel sind Payload?
Wie viel % der Pakete haben tatsächlich einen Payload und welche keinen (z.B. Acks)
Welche Flows gibt es? welche ist der Mainflow (nach Größe der pakete (normal) und nach paketanzahl)
Flow = Datenstrom (Welche Daten werden zwischen wem ausgetauscht, z.B. zwischen mir und YT)


Meeting 22.05.24

Pandas Dataframe googlen
performence verbessern

vorher eine Liste einlegen, weil Append gefährlich ist für die Performance
in eine Array die Anzahl der Pakete von allen AllNetworkTrafic (die erste Datei)
sortieren nach größe
plot von sortierten Liste

für Performance keine for-Schleife verwenden!
ChatGPT um hilfe fragen, um for-Schleifen zu vermeiden

Meeting 27.05.24

Statistiken

Wie viele Daten in den einzlnen Dateien
Wie groß sind die im Mittel
Wie groß ist die Bandbreite der Download Pakete


filling => Buffer wird gefüllt
depletion => Buffer wird geleert
stalling => Buffer ist leer


Meeting 03.06.24

pcaps streamen => übertragen von einem PC zum anderen wie bei Server und PC
Ressourcen = Ram und CPu Monitoren
Test wiederholen Respery Pi
Per Mail anschreiben nicht per RocketChat
Ziel: Verstehen wie die Datenanlyse

Paper von Wassermann (anschauen)
Wir versuchen mit hoher Effizienz
Wasser detailierte Analyse (effizienz egal)



Meeting 01.07.24

.pcap Streamen

Download anschauen
Upload anschauen

Ressourcenverbrauch anschauen und vergleichen (CPU mem (oder so) laufen lassen) CPU Info cutten
Befehl suchen um CPU auslastung anzuschauen


Noah hilft um Testset aufzubauen (einen Rechner aufsetzen als Traffic Source)
An diesem PC soll monitoring stattfinden

TCP Replay benutzen


Notizen für mein Verständnis:

Mit Hilfe von RCP Replay .pcaps streamen:
Befehl:
sudo tcpreplay --intf1=enp0s25 test.pcap
enp0s25 ist der Name von meinem Netzwerk Port
test.pcap ist der Name der .pcap Datei, die ich streamen möchte

CPU: Tracken
In den Systemeinstellungen kann man sich das graphisch anzeigen lassen
Befehl: gnome-system-monitor

Mit Hilfe von Collectd kann man das Monitoring auch speichern um es später analysieren zu können
Befehle:
In die Einstellungen zu kommen:
sudo nano /etc/collectd/collectd.conf

Statusabfrage:
sudo systemctl status collectd

Neustart (nach jeder Änderung in den Einstellung):
sudo systemctl restart collectd

Monitoring wird unter
/var/lib/collectd/csv/127.0.0.1
gespeichert

ssh Befehl um Zugriff auf Server-Rechner zu bekommen:
ssh david@10.0.0.1


Meeting 08.07.24 (letztes Meeting vor den Prüfungen)
cat /proc ...(im System finden)


erstmal Testnetz aufstellen und zur Probe .pcaps Streamen
=> wenn das steht, dann die großen .pcap Daten von Frank holen

Szenarien erstellen, um nicht alle .pcaps (sinnlos) zu streamen

Ergebnisse




Meeting 15.07.24

htop oder top für CPU live anzuschauen



Ein Script bauen:

sc = Script

auf server Script starten
zeit loggen (ersten timestamp (millisekunden reichen)
von Sc CPU erfassung starten
Befehl nice (CPU pinning) oder (linux CPU pinning)
vom sc daten streamen und captachern starten
untersuchen: Wie verhält sich die CPU
Wenn ich alle Daten Capture
nur Downlink oder nur Uplink
oder nur Uplink großer 200 oder 300 byte

FALLS: Ich bei linux CPU Monitoring nicht weiterkommen, dann bei Noah melden


Proseccing...




Meeting 05.08.24 (erstes Meeting nach Prüfungen)

cpu pinning (prozess auf einen Kern pinnen)
hard

cpu auslastung in % wird pro kern angegben nicht von allen zusammen

daten zur Auswertung
CPU
RAM

IO mit loggen zum Debuggen

Hauptfrage:
trace up und down vs nur down vs nur uplink

Meeting 19.08.24


genauere Auslastung betrachten (mehr als zwei Kommastellen)

Anzahl der Pakete pro Sekunde
Größe der Pakete pro Sekunde

CPU teilen durch Anzahl und durch Größe

Schauen wie die Kurve steigt bei Pakete und CPU Auslastung

Herausfinden wofür die CPU Auslastung benutzt wird

Mit verschiedenen Streamqualitäten



Meeting 26.08.24

*.pcap nutzen für dateipfad

inputpath = '/media/david/223ba2ff-1496-4758-9469-2564dd4f8b20/Logfiles/Wuerzburg_logs_1_1_18/Scenario_1/Vid_2d1VrCvdzbY'
inputfilenames = "*.pcap"
all_files = [file
             for path, subdir, files in os.walk(inputpath)
             for file in glob(os.path.join(path, inputfilenames))]

das ist aus dem Datensatz den wir mal runtergeladen haben in mobile_yt_dataset -> Material -> process_stats_for_nerds.py


Nicht nur weniger Pakete schicken, sondern auch beobachten wie sich das erhält, wenn man weniger Pakete beobachtet

TODO:

Ressourcen in einer CSV Datei speichern

verschiedene Straming .pcaps anschauen (haben die niedrigeren Qualitäten im Verhältnis mehr Upload Pakete?)
-> ggf. Script durchlaufen lassen, um zu beobachten, wie sich das auf Ressourcenverbrauch auswirkt

Script so anpassen, dass es die Daten von der Festplatte streamt


Meeting 02.09.24

Verschiedene Lasten im Upload beobachten (und Kurve beobachten)

Parallel mehrer Uploadflows schicken

Begriffe in der annotated.csv:
stalling: 0 -> kein Stalling, 1 -> Stalling tritt auf

qc: 0 -> kein Qualitätswechsel, 1 -> Qualitätswechsel
qcFrom = von welcher Qualität weg gewechselt wird
qcTo = zu welcher Qualität weg gewechselt wird

Zahlen auf Qualitäten auflösen (in Google schauen -> https://gist.github.com/sidneys/7095afe4da4ae58694d128b1034e01e2)
Besonders wichtig sind die Auflösungen von 242 bis 278


Zum CPU Verbrauch:
In der Datei /proc/"pid"/stat
Verbrauchte Zeit = 14th + 15th
Gesamte Zeit = 22th

CPU Auslastung in %: (14th + 15th) / 22th


Meeting 23.09.24

Wie viele Daten werden übertragen und in welchem Verhältnis steht das?

Wie steigen die einzelnen Ressourcen (CPU, und RAM)

Wie kann man IO beobachten, was und wie?



------------------- WICHTIG --------------------
Befehl um Python Scripte auszuführen:
sudo python3 "/home/david/PycharmProjects/matplotlibtesting/src/datenaustausch testbet/datenauswerten_down.py"
------------------------------------------------




Meeting 07.10.24

- Beim Beobachten vom Upload das Python Script selber betrachten

- Mal schauen ab wie viel Paketen das komische Ende mit den Nachkommastellen auftritt und ob dies konsitent auftritt
        Tritt leider in Bezug auf Pakete inkonsistent auf. (ab ca. 120 Paketen)


- Mit iperf -Python googlen den Datenverkehr generieren (siehe FireFox)


- Zum Beobachten von weniger Paketen, einfach die FrameNumber mit Modulo betrachten.
- thsark filter pid um die Frame Number zu finden im ip-Header


Meeting 14.10.24

CPU Verbrauch vergleichen mit Script und ohne Script
Verteilung Plotten (siehe Folien)

PDF -> Vertileungsdichtefunktion,
CDF -> Verteilungsfunktion x-Achse =CPU auslastung, y- p(das es kleiner ist),
Boxplot -> Zusammenfassung / Vergleich von Verteilungen

- In der Dokumentation von der Proc Datei schauen, wo die IO Times stehen
    Es ist zu sehen wie viele Bytes von der Anwendung gelesen und geschrieben werden

    Frage: Bekommt man auch die relative IO Time?
    Also ingesamte IO Time geteilt durch benutzte IO Time -> Gibt an wie viel IO Time der Prozess verwendet hat

- Anschauen, ob das Beobachten von weniger Paketen zu weniger CPU auslastung führt via vorherigen Filter (TC - Trafic Control)
    Vorheriges filtern ist nicht möglich, cpu auslastung ist ziemlich identisch

    Andere Möglichkeit: mit net-em qdisc und dem lost befehl einen prozentsatz von Paketen einfah zu droppen
        mit der State config spielen um zu schauen, dass nur jedes x paket ankommt
         LOSS := loss { random PERCENT [ CORRELATION ]  |
                      state p13 [ p31 [ p32 [ p23 [ p14]]]] |
                      gemodel p [ r [ 1-h [ 1-k ]]] }  [ ecn ]


(Nur als Hinweis - zum Aufsetzen von einem Streaming Server jellyfin)


Meeting 28.10.24

- In der Dokumentation von der Proc Datei schauen, wo die IO Times stehen
    Es ist zu sehen wie viele Bytes von der Anwendung gelesen und geschrieben werden

    Frage: Bekommt man auch die relative IO Time?
    Also ingesamte IO Time geteilt durch benutzte IO Time -> Gibt an wie viel IO Time der Prozess verwendet hat
        Antwort: Nein es gibt keine Möglichkeit aus der Proc Datei die IO Time auszulesen,
                 aber vielleicht ist es interessant die Children vom Porzess zu betrachten,
                 vielleicht wird da auch die IO dazugeszählt.
                 pr_utime
                    Specifies the user CPU time consumed by the process
                 pr_stime
                    Specifies the system CPU process time consumed by the process
                 pr_cutime
                    Specifies the cumulative user CPU time consumed by the children of the process, expressed in seconds and nanoseconds
                 pr_cstime
                    Specifies the cumulative system CPU time, in seconds and nanoseconds, consumed by the process's children


- Der Filter mit der Trafic Controll funktioniert (mit Hilfe von netem)
    Ich weiß noch nicht, wie groß die CPU Leistungs-Einsparung ist, aber auf jeden Fall geringer.
    Frage: Soll ich die CPU Leistung der TC auch messen und sie addieren oder so?
        -> Ist das überhaupt möglich? Mal schauen, ob ich mit der PID sinnvolle Daten bekomme.


Meeting 04.11.24

- In der Proc Datei die children anschauen (direkt vom Script)

- für die Arbeit mit venv
    Innerhalb vom venv muss noch jede bib installiert werden (entweder mit pip oder mit dem requirements.txt -> eine Datei mir den Versionen der importe)


Meeting 11.11.24

Down-Up und beide aufzeichnen

und das Verhältnis der CPU anschauen

Anzahl der Pakete von Up und Down Link
die Bytes (also den Durchsatz)

Gibt es Korelationen zwischen Byte und CPU oder Pakteanahl und CPU?

Was spare ich wenn ich nur xte Paket anschaue korreliert das mit der CPU?

Mit IPERF versenden 300 kilobit bis 50 megabit

Verhältnis zwischen der bandbreite und der CPU Auslastung


(Nächster Schritt Zusammenhang zwischen Qualität und Energieverbrauch)


TODO

1. Download tracken bei einer pcap Datei
2. Upload tracken bei der selben pcap Datei

3. Jeweils die CPU Auslastung vergleichen mit der Paketanzahl pro Sekunde, Byteanzahl pro Sekunde. Mit dem Python Script Daten versenden

4. Filter anwenden: Schauen, wie viele CPU Auslatung zu sparen ist, wenn man nur jedes x. Paket betrachtet

5. IPERF Server aufsetzen und verschiedene Bandbreiten beobachten


Meeting 18.11.24

- Testergebnisse zu Downlod mit und ohne Filter und Upload
    - Donwload wie erwartet am schlechtesten
    - Download mit Filter etwas besser
    - Nur Upload deutlich besser

    Download:           1.5292755751787697
    Upload:             0.23613110452671227
    Download Filter:    1.2471710062942847

- CPU über die Zeit betrachten (als Plot)
- FRAGE: Wie und was kann ich besseres Beobachten als den Mittelwert

- CDF, für verschiedene entweder mehrere CDFs oder Boxplots

- Frage: Wie kann ich mithilfe des Scriptes verschiedene Datenmengen verschicken?

Nochmal zum RAM:
Kann man herausfinden, wie viel aktuell verwendet wird. Bzw, was ist der aktuelle Wert genau? Angeforderter Speicehr vom Prozess

- Zeit in Millisekunden seit 1970 (also der Unix TimeStamp)
- frame.time -epoche in tshark oder als Timepacket in Python


- Kurve von jedem xten Paket

- Idee: Ein Script, dass verschiedene Datenraten verwendet.


TODO:

1. Änderungen an Messung vornehmen:
    1.1: Was ist das für eine Angabe beim RAM? KB oder MB
    - Ist in KB (proc.memory_info().rss gibt es in Byte aus und ich teile den Wert durch 1024, was dann KiloByte ergibt)
        1.1.1: Was stellt der aktuelle Wert dar?
            Kann man herausfinden, wie viel aktuell verwendet wird. Bzw, was ist der aktuelle Wert genau? Angeforderter Speicehr vom Prozess
            - Der aktuell verbauchte RAM
            Aus der Dokumentation:
                rss: aka “Resident Set Size”, this is the non-swapped physical memory a process has used. On UNIX it matches “top“‘s RES column). On Windows this is an alias for wset field and it matches “Mem Usage” column of taskmgr.exe.
                vms: aka “Virtual Memory Size”, this is the total amount of virtual memory used by the process. On UNIX it matches “top“‘s VIRT column. On Windows this is an alias for pagefile field and it matches “Mem Usage” “VM Size” column of taskmgr.exe.

                Beides sind konstante Werte...

    1.2: Die Zeiteinheit ändern in Sekunden seit 1970 und am besten mit Millisekunden
            - Zeit in Millisekunden seit 1970 (also der Unix TimeStamp)
            - frame.time -epoche in tshark oder als Timepacket in Python

            mit Python gelöst: time.time_ns()

2. Code für Datenauswertung schreiben:
    °2.1: Plot von CPU Auslastung über die Zeit
    °2.2: CPU Auslastung in Zusammenhang mit Paketanzahl bringen (mit Plot)
    2.3: CPU Auslastung in Zusammenahng mit Durchsatz bringen (mit Plot)

3. Weitere Messungen:
    3.1: datensenden_test.py anpassen, um verschiedene Daten und Paket-Raten versenden zu können.
    3.2: Script schreiben, um die verschiedenen Datenraten nacheinander abzuspielen.
    3.3: Script schreiben, das die Download CPU Auslastung mit verschiedenen Filter nacheinander trackt
        3.3.1: Die Kurve der CPU Leistung plotten (mit immer weniger Paketen sinkt wie genau die CPU Auslastung)

Meeting 03.12.24

Das ursprünglich Script für das Generieren von Trafic, hat keinen Upload, den man betrachten möchte, also mit iperf generieren
Die Qualität steigt in Stufen an und die Bitrate kontinuierlich, dadurch wollen wir möglich genau die Bitrate die für die akteulle Qualität vergeben,
um keine unnötig hohe Bitrate für die Qualität zu haben und sozusagen bitrate zu verschenken, die uns keine bessere QoE bringt.

TODO:
Zum Datensatz:
Die Python File evtl mal anschauen aber nicht so wichtig
new und old sind die Zeitpunkte der Messung
old1 und 2 sind nicht so relevant

Datum wann gemessen wurde und was das Ziel ist (Stalling oder so triggern).
Am besten das Streamen der Daten über die Annoted.csv mit Hilfe von Python generieren. Der Vorteil daran ist, dass man direkt die Anwendungsdaten wie Stalling, Qualität und so weiter einsehen kann.

Erstmal weiter machen und die Kurve für die CPU Auslastung über die Zeit Paketanzahl bzw. Durchsatz anschauen

Zusätzlich das Paper lesen, um die Idee von der Qualität in Beziehung zur Bitrate zu verstehen
Paper von Frank Loh mit dem Namen:
"Industrial User Experience Index
vs. Quality of Experience Models"
zu finden auf Google Scholar




Meeting 09.12.24

- Darstellung der Kurve von CPU-Auslatung über die Datenrate ist gelungen
    - Aber die Darstellung der Download Ressorcen sind seltsam, noch unbekannt wesshalb.
        Frage: Wieso ist das so? (Kann es sein das der Filter falsch gesetzt ist?)

Frage: Beim Erstellen der Kurve von CPU-Auslastung über die Paketanzahl: Wie soll ich die Parameter dafür einstellen?
Um so mehr Pakete mit Größe X gesendet werden, desto größer wird ja auch die Datenrate.
Soll ich also die Größe der Pakete anändern, damit die Datenrate konstant bleibt? Oder ist es ok/gewollt, wenn die Datenrate mit ansteigt?

Frage: Soll ich die Messpunkte überhaupt logarithmisch auftragen und reichen uns dabei 15 Messpunkte?

Noch offen: erstellen vom Plot CPU Auslastung über Paketanzahl




Nachschauen in welcher Einheit die Proc Datei steht?

Mit den realten Datensätzen
    Was sind die Max Datenraten für Up und Downlink?
    Und für Downlink mit einem 4K Stream.

Nächster Schritt Stromverbrauch beobachten.



Um das Problem mit dem Download Filter
die Befehle mit dem Termianl ausführen und die pcap Dateien anschauen,
ob sie wie erwartet aussehen.

Jeden Test 10 Minuten und 30 Sek lang und innerhalb der 10 Minuten die
CPU Auslastung über die Zeit anschauen

Innerhalb schaune wann die Werte sich eingependelt haben
dann Batchmean bilden, also 100 Intervalle bilden und jeweils den Mittelwert
Daraus Konfidenz Intervalle bilden

Verschiedene Intervalle von 10² - 10³, 10³ - 10⁴, 10⁴ - 10⁵
für diese Intervalle jeweils eine logarithmische Aufteilung machen und damit die Auflösung erhöhen

TODO:
Am Ende noch die Sache mit den Paketen anschauen
Im Donwlink mit Paketgröße mit 1500 byte und im Uplink mit
kleinerer Paketgröße

für den Uplink in der request.csv und dann gewichtete Summe erstellen
einen zweidimensionalen Array mit dem mean und dem count der Pakete

In den Simtech Folien den Hintergrund nachlesen

WICHTIG: Zu nächster Woche mal alles in Slites zusammenfassen und strukturieren



Meeting 15.01.25:

Eine detaillierte Beschreibung der Messung
in Stichpunkten
von Paket kommt an, bis zum Ergebnis

Beschreibung von Testbed

Die RohDaten von dem Plot longtest

Dazu noch die Info zum RAM

Wie viel Strom braucht die CPU? Herausfinden... mal anschauen Perfomance Counter
    Man findet die maximal Watt Leistung der CPU, aber keinen Anstieg über die Utilization der einen Graph o.ä.
    Thermal Design Power (TDP) ist für diese CPU 84 Watt

    Mit dem Performance Counter kann man theorethische Modelle dazu erstellen wie viel Energie die CPU theoretisch verbraucht


    ToDo:
    
    Beides für mich zum Lernen, nicht relevant für das Paper oder so

    1.
    Langzeitverhalten der CPU utilizatiopn betrachten
    Intervall der Sendung 1 Stunde
    20 Replikationen
    steady State finden
    Batch Means berechnen


    2.
    Im Datensatz nach drei Videos suchen die eine lange steady Phase haben
    Plott von der Zeit zwischen den Requeste
    x-Achse - Zeit
    y-Achse - Zeit zwischen den Request

    mindestens 100 Sekunden land steady

    falls ich ein charakteristisches Muster sehe, überlegen warum, falls nicht, muss ich schauen, was ich falsch gemaccht habe (vllt. anderes Video)



















