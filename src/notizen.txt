Meeting 02.05.24

über die Zeit betrachten, mit der Zeitspalte frame.time_epoche
y = Zeit, x = nicht alle Pakete als Summe, sondern Pakete bzw. Byte pro Sec.
Videostreams in verschiedenen Qualitäten anfordern und vergleichen in einem gemeinsamen Plot
wie viel von der frame.len nur header, wie viel sind Payload?
Wie viel % der Pakete haben tatsächlich einen Payload und welche keinen (z.B. Acks)
Welche Flows gibt es? welche ist der Mainflow (nach Größe der pakete (normal) und nach paketanzahl)
Flow = Datenstrom (Welche Daten werden zwischen wem ausgetauscht, z.B. zwischen mir und YT)


Meeting 22.05.24

Pandas Dataframe googlen
performence verbessern

vorher eine Liste einlegen, weil Append gefährlich ist für die Performance
in eine Array die Anzahl der Pakete von allen AllNetworkTrafic (die erste Datei)
sortieren nach größe
plot von sortierten Liste

für Performance keine for-Schleife verwenden!
ChatGPT um hilfe fragen, um for-Schleifen zu vermeiden

Meeting 27.05.24

Statistiken

Wie viele Daten in den einzlnen Dateien
Wie groß sind die im Mittel
Wie groß ist die Bandbreite der Download Pakete


filling => Buffer wird gefüllt
depletion => Buffer wird geleert
stalling => Buffer ist leer


Meeting 03.06.24

pcaps streamen => übertragen von einem PC zum anderen wie bei Server und PC
Ressourcen = Ram und CPu Monitoren
Test wiederholen Respery Pi
Per Mail anschreiben nicht per RocketChat
Ziel: Verstehen wie die Datenanlyse

Paper von Wassermann (anschauen)
Wir versuchen mit hoher Effizienz
Wasser detailierte Analyse (effizienz egal)



Meeting 01.07.24

.pcap Streamen

Download anschauen
Upload anschauen

Ressourcenverbrauch anschauen und vergleichen (CPU mem (oder so) laufen lassen) CPU Info cutten
Befehl suchen um CPU auslastung anzuschauen


Noah hilft um Testset aufzubauen (einen Rechner aufsetzen als Traffic Source)
An diesem PC soll monitoring stattfinden

TCP Replay benutzen


Notizen für mein Verständnis:

Mit Hilfe von RCP Replay .pcaps streamen:
Befehl:
sudo tcpreplay --intf1=enp0s25 test.pcap
enp0s25 ist der Name von meinem Netzwerk Port
test.pcap ist der Name der .pcap Datei, die ich streamen möchte

CPU: Tracken
In den Systemeinstellungen kann man sich das graphisch anzeigen lassen
Befehl: gnome-system-monitor

Mit Hilfe von Collectd kann man das Monitoring auch speichern um es später analysieren zu können
Befehle:
In die Einstellungen zu kommen:
sudo nano /etc/collectd/collectd.conf

Statusabfrage:
sudo systemctl status collectd

Neustart (nach jeder Änderung in den Einstellung):
sudo systemctl restart collectd

Monitoring wird unter
/var/lib/collectd/csv/127.0.0.1
gespeichert

ssh Befehl um Zugriff auf Server-Rechner zu bekommen:
ssh david@10.0.0.1


Meeting 08.07.24 (letztes Meeting vor den Prüfungen)
cat /proc ...(im System finden)


erstmal Testnetz aufstellen und zur Probe .pcaps Streamen
=> wenn das steht, dann die großen .pcap Daten von Frank holen

Szenarien erstellen, um nicht alle .pcaps (sinnlos) zu streamen

Ergebnisse




Meeting 15.07.24

htop oder top für CPU live anzuschauen



Ein Script bauen:

sc = Script

auf server Script starten
zeit loggen (ersten timestamp (millisekunden reichen)
von Sc CPU erfassung starten
Befehl nice (CPU pinning) oder (linux CPU pinning)
vom sc daten streamen und captachern starten
untersuchen: Wie verhält sich die CPU
Wenn ich alle Daten Capture
nur Downlink oder nur Uplink
oder nur Uplink großer 200 oder 300 byte

FALLS: Ich bei linux CPU Monitoring nicht weiterkommen, dann bei Noah melden


Proseccing...




Meeting

cpu pinning (prozess auf einen Kern pinnen)
hard

cpu auslastung in % wird pro kern angegben nicht von allen zusammen

daten zur Auswertung
CPU
RAM

IO mit loggen zum Debuggen

Hauptfrage:
trace up und down vs nur down vs nur uplink















